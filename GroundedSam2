# GroundedSam2

## 개요
GroundedSam2는 **RGB 사진**을 기반으로 한 가구 인식 및 크기 추정을 수행하는 모델입니다. 이 시스템은 사용자가 제공한 텍스트 프롬프트에 따라 사진 속에서 특정 객체를 탐지하고, 해당 객체의 세그멘테이션 및 크기 분석을 통해 관련 정보를 제공합니다. 이러한 정보를 활용하여 가구 추천과 같은 다양한 응용 프로그램에 적용할 수 있습니다.

---

## 주요 기능
1. **텍스트 기반 객체 탐지**:
   - **Grounding DINO**를 사용하여 입력된 텍스트 프롬프트에 따라 객체를 탐지합니다.
   - "모니터. 텀블러."와 같은 간단한 텍스트 입력을 지원하며, 다양한 가구 및 물체를 식별할 수 있습니다.

2. **정확한 이미지 세분화**:
   - **SAM2 (Segment Anything Model)**을 사용하여 탐지된 객체를 픽셀 단위로 정확히 세분화합니다.
   - Grounding DINO에서 생성된 경계 상자를 바탕으로 세분화 결과를 더욱 정교하게 만듭니다.

3. **크기 추정 및 분석**:
   - 탐지된 객체의 세그멘테이션 데이터를 활용하여 크기(너비, 높이)를 추정합니다.
   - 추정된 크기를 기반으로 가구 배치나 추천 시스템에 유용한 데이터를 제공합니다.

4. **시각화 및 결과 저장**:
   - 세그멘테이션 마스크와 탐지된 객체를 시각적으로 표현하여 사용자가 결과를 쉽게 이해할 수 있도록 돕습니다.
   - 탐지 및 세그멘테이션 결과를 JSON 파일로 저장하여 후속 처리에 활용할 수 있습니다.

5. **CUDA 가속 지원**:
   - PyTorch와 CUDA를 활용하여 빠른 추론 속도를 제공합니다.

---

## 알고리즘 파이프라인
GroundedSam2의 주요 알고리즘은 다음 단계로 구성됩니다:

### 1. 초기화
- **모델 로드**:
  - 텍스트 기반 객체 탐지를 위한 Grounding DINO 모델 로드.
  - 정확한 세분화를 위한 SAM2 모델 로드.
- **하이퍼파라미터 설정**:
  - 텍스트 프롬프트, 임계값, 모델 구성 및 장치 설정.

### 2. 전처리
- 입력 이미지를 로드하고 추론을 위한 전처리 수행.
- 텍스트 프롬프트는 소문자로 변환하고 마침표를 포함해야 합니다 (예: "모니터. 텀블러.").

### 3. 객체 탐지
- **Grounding DINO**를 사용하여 텍스트 프롬프트에 따라 경계 상자, 라벨, 신뢰도를 추론.
- 경계 상자를 원본 이미지 해상도에 맞게 조정.

### 4. 이미지 세분화
- 탐지된 경계 상자를 **SAM2**에 전달하여 세그멘테이션 마스크 생성.
- 각 객체에 대해 정확한 이진 마스크 생성.

### 5. 후처리 및 크기 추정
- 세그멘테이션 결과를 사용하여 탐지된 객체의 크기를 추정.
- 추정된 크기는 가구 배치 시뮬레이션 및 추천 시스템에 활용 가능.

### 6. 결과 시각화 및 저장
- 탐지된 객체를 경계 상자, 세그멘테이션 마스크, 라벨과 함께 시각화.
- JSON 파일로 결과 저장:
  ```json
  {
    "image_path": "test_image/size.jpg",
    "annotations": [
      {
        "class_name": "monitor",
        "bbox": [100, 50, 200, 150],
        "segmentation": {"counts": "encoded_string", "size": [height, width]},
        "score": 0.95
      }
    ],
    "box_format": "xyxy",
    "img_width": 1920,
    "img_height": 1080
  }
  ```

---

## 의존성
GroundedSam2는 다음과 같은 라이브러리와 모델을 사용합니다:
- **PyTorch**: 모델 추론.
- **Grounding DINO**: 텍스트 기반 객체 탐지.
- **SAM2**: 이미지 세분화.
- **Supervision API**: 시각화 도구.
- **pycocotools**: 세그멘테이션 마스크 처리.
- **OpenCV**: 이미지 처리.

---

## 사용 예시
GroundedSam2를 사용하려면:

1. **환경 설정**:
   - 의존성을 설치합니다.
   - Grounding DINO와 SAM2의 체크포인트 파일을 지정된 경로에 배치합니다.

2. **스크립트 실행**:
   ```bash
   python grounded_sam2.py
   ```

3. **결과 확인**:
   - 결과 이미지(주석 처리 포함)는 `result` 디렉토리에 저장됩니다.
   - 탐지 결과는 `results.json` 파일에 저장됩니다.

---

## 활용 가능성
- 가구 배치 시뮬레이션 및 추천 시스템.
- 로봇 비전 기반 가구 탐지 및 상호작용.
- 데이터셋 분석 및 레이블링.

---

## 한계
- 최적의 성능을 위해 GPU 가속이 필요합니다.
- 탐지 정확도는 입력 텍스트 프롬프트와 이미지 품질에 따라 달라질 수 있습니다.

---

GroundedSam2는 텍스트 기반 객체 탐지 및 크기 추정을 통해 RGB 사진을 활용한 다양한 응용 프로그램에 기여할 수 있는 강력하고 유연한 도구입니다.

